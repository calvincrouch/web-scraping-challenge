{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NASA Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the mars news site for text\n",
    "\n",
    "#URL\n",
    "url = \"https://redplanetscience.com/\"\n",
    "browser.visit(url)\n",
    "time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(1):\n",
    "    \n",
    "    html = browser.html\n",
    "    # Parse HTML with Beautiful Soup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    list_text = soup.find_all('div', class_='list_text')\n",
    "\n",
    "    for list_ in list_text:\n",
    "        \n",
    "        title = list_.find(\"div\", {\"class\": \"content_title\"}).get_text()\n",
    "        paragraph = list_.find(\"div\", {\"class\": \"article_teaser_body\"}).get_text()\n",
    "        print('-----------')\n",
    "        print(title)\n",
    "        print(paragraph)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPL Mars Space Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape pictures of mars from space images site\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpl_url = \"https://spaceimages-mars.com/\"\n",
    "browser.visit(jpl_url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "# Parse HTML with Beautiful Soup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "images = soup.find('img', class_='headerimage')\n",
    "\n",
    "# Retrieve src element\n",
    "src = (images['src'])\n",
    "\n",
    "featured_image_url = f\"{jpl_url}{src}\"\n",
    "featured_image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to scrape table of facts from Mars Facts Webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_url = \"https://galaxyfacts-mars.com/\"\n",
    "browser.visit(facts_url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = pd.read_html(facts_url)\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_df = tables[0]\n",
    "facts_df.columns = ['Description', \"Mars\", \"Earth\"]\n",
    "facts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_table = facts_df.to_html()\n",
    "html_table = html_table.replace('\\n', '')\n",
    "html_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Hemisphere's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape Mars astrogeology image data for mars' hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemi_url = \"https://marshemispheres.com/\"\n",
    "browser.visit(hemi_url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemi_html = browser.html\n",
    "# Parse HTML with Beautiful Soup\n",
    "soup2 = BeautifulSoup(hemi_html, 'html.parser')\n",
    "divs = soup2.find_all('div', class_='item')\n",
    "\n",
    "# Create a variable to add a list of href's\n",
    "href_list = []\n",
    "\n",
    "for div in divs:\n",
    "    a = div.find('a')\n",
    "    href = a['href']\n",
    "    href_list.append(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use href_list to scrape\n",
    "\n",
    "all_titles = []\n",
    "all_src = []\n",
    "for x in href_list:\n",
    "    \n",
    "    base_url = \"https://marshemispheres.com/\"\n",
    "    urlhref = f\"{base_url}{x}\"\n",
    "    browser.visit(urlhref)\n",
    "    \n",
    "    html3 = browser.html\n",
    "    # Parse HTML with Beautiful Soup\n",
    "    soup = BeautifulSoup(html3, 'html.parser')\n",
    "    anchors = soup.find_all('img', class_='wide-image')\n",
    "    titles = soup.find_all('h2', class_='title')\n",
    "    \n",
    "    # Iterate through each title\n",
    "    for ti in titles:\n",
    "        title2 = ti.get_text()\n",
    "        all_titles.append(title2)\n",
    "        print('-----------')\n",
    "        print(title2)\n",
    "    \n",
    "    for anchor in anchors:\n",
    "        src = anchor['src']\n",
    "        img_url = base_url + src\n",
    "        all_src.append(img_url)\n",
    "        print(f'{img_url}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_image_urls = []\n",
    "for i, j in zip(all_titles, all_src):\n",
    "    hemisphere_image_urls.append({\"title\": i, \"img_url\": j})\n",
    "hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
